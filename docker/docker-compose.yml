version: '3.8'

services:
  llm-context-prep:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    image: llm-context-prep-mcp:latest
    container_name: llm-context-prep-mcp

    # Run HTTP transport so you get a URL endpoint (change to sse if you prefer)
    stdin_open: false
    tty: false
    command: ["python", "src/mcp_server_fastmcp.py", "--transport", "http", "--port", "8847"]

    ports:
      - "8847:8847"

    volumes:
      - ${WORKSPACE_DIR:-./workspace}:/workspace

    environment:
      - MCP_DEBUG=${MCP_DEBUG:-false}
      - MCP_MAX_FILE_SIZE=${MCP_MAX_FILE_SIZE:-10485760}
      - MCP_MAX_CONTEXT_SIZE=${MCP_MAX_CONTEXT_SIZE:-52428800}
      - MCP_DOCKER_MODE=true
      - MCP_WORKSPACE_DIR=/workspace
      - MCP_ALLOWED_EXTENSIONS=${MCP_ALLOWED_EXTENSIONS:-.py,.js,.ts,.md,.txt,.json,.yaml,.yml}

    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

    security_opt:
      - no-new-privileges:true
    read_only: false

volumes:
  workspace:
    driver: local

